{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week12.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "umbkUp5Y8PfS",
        "outputId": "bc82f606-ae26-4a4f-ea23-a5f78f765d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l\n",
            "  Downloading d2l-0.17.3-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 342 kB/s \n",
            "\u001b[?25hCollecting matplotlib==3.3.3\n",
            "  Downloading matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 24.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.0.0)\n",
            "Collecting requests==2.25.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting pandas==1.2.2\n",
            "  Downloading pandas-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 46.5 MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.5\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.2.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (7.6.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (1.3.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (3.0.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.2->d2l) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2021.10.8)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.3.3->d2l) (1.15.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (1.0.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (5.1.3)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.5.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.9.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (0.18.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.10.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (3.7.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (2.11.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter==1.0.0->d2l) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->d2l) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter==1.0.0->d2l) (2.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (21.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.0.0)\n",
            "Installing collected packages: numpy, requests, pandas, matplotlib, d2l\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed d2l-0.17.3 matplotlib-3.3.3 numpy-1.18.5 pandas-1.2.2 requests-2.25.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install d2l"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from d2l import tensorflow as d2l\n",
        "\n",
        "\n",
        "def net():\n",
        "    return tf.keras.models.Sequential([\n",
        "        # Here, we use a larger 11 x 11 window to capture objects. At the same\n",
        "        # time, we use a stride of 4 to greatly reduce the height and width of\n",
        "        # the output. Here, the number of output channels is much larger than\n",
        "        # that in LeNet\n",
        "        tf.keras.layers.Conv2D(filters=96, kernel_size=11, strides=4,\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        # Make the convolution window smaller, set padding to 2 for consistent\n",
        "        # height and width across the input and output, and increase the\n",
        "        # number of output channels\n",
        "        tf.keras.layers.Conv2D(filters=256, kernel_size=5, padding='same',\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        # Use three successive convolutional layers and a smaller convolution\n",
        "        # window. Except for the final convolutional layer, the number of\n",
        "        # output channels is further increased. Pooling layers are not used to\n",
        "        # reduce the height and width of input after the first two\n",
        "        # convolutional layers\n",
        "        tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same',\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        # Here, the number of outputs of the fully-connected layer is several\n",
        "        # times larger than that in LeNet. Use the dropout layer to mitigate\n",
        "        # overfitting\n",
        "        tf.keras.layers.Dense(4096, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(4096, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        # Output layer. Since we are using Fashion-MNIST, the number of\n",
        "        # classes is 10, instead of 1000 as in the paper\n",
        "        tf.keras.layers.Dense(10)\n",
        "    ])"
      ],
      "metadata": {
        "id": "VKfwvuOvHo7w"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.random.uniform((1, 224, 224, 1))\n",
        "for layer in net().layers:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArnsaSuSHsPH",
        "outputId": "3f339e4b-a2b0-40be-d5ea-5b4a0ab7fdb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2D output shape:\t (1, 54, 54, 96)\n",
            "MaxPooling2D output shape:\t (1, 26, 26, 96)\n",
            "Conv2D output shape:\t (1, 26, 26, 256)\n",
            "MaxPooling2D output shape:\t (1, 12, 12, 256)\n",
            "Conv2D output shape:\t (1, 12, 12, 384)\n",
            "Conv2D output shape:\t (1, 12, 12, 384)\n",
            "Conv2D output shape:\t (1, 12, 12, 256)\n",
            "MaxPooling2D output shape:\t (1, 5, 5, 256)\n",
            "Flatten output shape:\t (1, 6400)\n",
            "Dense output shape:\t (1, 4096)\n",
            "Dropout output shape:\t (1, 4096)\n",
            "Dense output shape:\t (1, 4096)\n",
            "Dropout output shape:\t (1, 4096)\n",
            "Dense output shape:\t (1, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read datasets\n",
        "\n",
        "batch_size = 128\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrGJIN-tHufT",
        "outputId": "2ce075b4-583b-49fd-e387-ab17b529d98a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WEEK12_VGG**"
      ],
      "metadata": {
        "id": "cJUisiAJJYaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from d2l import tensorflow as d2l\n",
        "\n",
        "\n",
        "def vgg_block(num_convs, num_channels):\n",
        "    blk = tf.keras.models.Sequential()\n",
        "    for _ in range(num_convs):\n",
        "        blk.add(tf.keras.layers.Conv2D(num_channels,kernel_size=3,\n",
        "                                    padding='same',activation='relu'))\n",
        "    blk.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "    return blk"
      ],
      "metadata": {
        "id": "PkXL0bVtJcTQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))"
      ],
      "metadata": {
        "id": "02YCOJLvJfHZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg network\n",
        "\n",
        "def vgg(conv_arch):\n",
        "    net = tf.keras.models.Sequential()\n",
        "    # The convulational part\n",
        "    for (num_convs, num_channels) in conv_arch:\n",
        "        net.add(vgg_block(num_convs, num_channels))\n",
        "    # The fully-connected part\n",
        "    net.add(tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(4096, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(4096, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(10)]))\n",
        "    return net\n",
        "\n",
        "net = vgg(conv_arch)"
      ],
      "metadata": {
        "id": "6kSodcjdJkhA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.random.uniform((1, 224, 224, 1))\n",
        "for blk in net.layers:\n",
        "    X = blk(X)\n",
        "    print(blk.__class__.__name__,'output shape:\\t', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZE44ahrMNac",
        "outputId": "20a1d0e8-7580-428d-ee3b-f6a24dd42f63"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential output shape:\t (1, 112, 112, 64)\n",
            "Sequential output shape:\t (1, 56, 56, 128)\n",
            "Sequential output shape:\t (1, 28, 28, 256)\n",
            "Sequential output shape:\t (1, 14, 14, 512)\n",
            "Sequential output shape:\t (1, 7, 7, 512)\n",
            "Sequential output shape:\t (1, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratio = 4\n",
        "small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]\n",
        "# Recall that this has to be a function that will be passed to\n",
        "# `d2l.train_ch6()` so that model building/compiling need to be within\n",
        "# `strategy.scope()` in order to utilize the CPU/GPU devices that we have\n",
        "net = lambda: vgg(small_conv_arch)"
      ],
      "metadata": {
        "id": "Nr9Rpmy6Mbp9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WEEK12_NIN**"
      ],
      "metadata": {
        "id": "RCCBX3jCNEgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from d2l import tensorflow as d2l\n",
        "\n",
        "\n",
        "def nin_block(num_channels, kernel_size, strides, padding):\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(num_channels, kernel_size, strides=strides,\n",
        "                               padding=padding, activation='relu'),\n",
        "        tf.keras.layers.Conv2D(num_channels, kernel_size=1,\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.Conv2D(num_channels, kernel_size=1,\n",
        "                               activation='relu')])"
      ],
      "metadata": {
        "id": "ea_5FUdYNLsU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model NIN"
      ],
      "metadata": {
        "id": "i6hkbIJ4Nj8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def net():\n",
        "    return tf.keras.models.Sequential([\n",
        "        nin_block(96, kernel_size=11, strides=4, padding='valid'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        nin_block(256, kernel_size=5, strides=1, padding='same'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        nin_block(384, kernel_size=3, strides=1, padding='same'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        # There are 10 label classes\n",
        "        nin_block(10, kernel_size=3, strides=1, padding='same'),\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Reshape((1, 1, 10)),\n",
        "        # Transform the four-dimensional output into two-dimensional output\n",
        "        # with a shape of (batch size, 10)\n",
        "        tf.keras.layers.Flatten(),\n",
        "        ])"
      ],
      "metadata": {
        "id": "3BBhWx3TNlHx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create data example\n",
        "\n",
        "X = tf.random.uniform((1, 224, 224, 1))\n",
        "for layer in net().layers:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVSI63f_Nulg",
        "outputId": "456e275d-ce14-4900-ffa9-9ec9dd101cca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential output shape:\t (1, 54, 54, 96)\n",
            "MaxPooling2D output shape:\t (1, 26, 26, 96)\n",
            "Sequential output shape:\t (1, 26, 26, 256)\n",
            "MaxPooling2D output shape:\t (1, 12, 12, 256)\n",
            "Sequential output shape:\t (1, 12, 12, 384)\n",
            "MaxPooling2D output shape:\t (1, 5, 5, 384)\n",
            "Dropout output shape:\t (1, 5, 5, 384)\n",
            "Sequential output shape:\t (1, 5, 5, 10)\n",
            "GlobalAveragePooling2D output shape:\t (1, 10)\n",
            "Reshape output shape:\t (1, 1, 1, 10)\n",
            "Flatten output shape:\t (1, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WEEK12_GoogleInetLogs**"
      ],
      "metadata": {
        "id": "ojsRnudfOxnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from d2l import tensorflow as d2l\n",
        "\n",
        "\n",
        "class Inception(tf.keras.Model):\n",
        "    # `c1`--`c4` are the number of output channels for each path\n",
        "    def __init__(self, c1, c2, c3, c4):\n",
        "        super().__init__()\n",
        "        # Path 1 is a single 1 x 1 convolutional layer\n",
        "        self.p1_1 = tf.keras.layers.Conv2D(c1, 1, activation='relu')\n",
        "        # Path 2 is a 1 x 1 convolutional layer followed by a 3 x 3\n",
        "        # convolutional layer\n",
        "        self.p2_1 = tf.keras.layers.Conv2D(c2[0], 1, activation='relu')\n",
        "        self.p2_2 = tf.keras.layers.Conv2D(c2[1], 3, padding='same',\n",
        "                                           activation='relu')\n",
        "        # Path 3 is a 1 x 1 convolutional layer followed by a 5 x 5\n",
        "        # convolutional layer\n",
        "        self.p3_1 = tf.keras.layers.Conv2D(c3[0], 1, activation='relu')\n",
        "        self.p3_2 = tf.keras.layers.Conv2D(c3[1], 5, padding='same',\n",
        "                                           activation='relu')\n",
        "        # Path 4 is a 3 x 3 maximum pooling layer followed by a 1 x 1\n",
        "        # convolutional layer\n",
        "        self.p4_1 = tf.keras.layers.MaxPool2D(3, 1, padding='same')\n",
        "        self.p4_2 = tf.keras.layers.Conv2D(c4, 1, activation='relu')\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "        p1 = self.p1_1(x)\n",
        "        p2 = self.p2_2(self.p2_1(x))\n",
        "        p3 = self.p3_2(self.p3_1(x))\n",
        "        p4 = self.p4_2(self.p4_1(x))\n",
        "        # Concatenate the outputs on the channel dimension\n",
        "        return tf.keras.layers.Concatenate()([p1, p2, p3, p4])"
      ],
      "metadata": {
        "id": "nHSGGZbuPHMK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second module uses two convolutional layers: first, a 64-channel 1×1 convolutional layer, then a 3×3 convolutional layer that triples the number of channels. This corresponds to the second path in the Inception block."
      ],
      "metadata": {
        "id": "jY6llFa1QjXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The first module uses a 64-channel  7×7  convolutional layer.\n",
        "\n",
        "def b1():\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(64, 7, strides=2, padding='same',\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])"
      ],
      "metadata": {
        "id": "9OVbf5VaPHSi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def b3():\n",
        "    return tf.keras.models.Sequential([\n",
        "        Inception(64, (96, 128), (16, 32), 32),\n",
        "        Inception(128, (128, 192), (32, 96), 64),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])"
      ],
      "metadata": {
        "id": "Rvj2YxuTQQPV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def b4():\n",
        "    return tf.keras.Sequential([\n",
        "        Inception(192, (96, 208), (16, 48), 64),\n",
        "        Inception(160, (112, 224), (24, 64), 64),\n",
        "        Inception(128, (128, 256), (24, 64), 64),\n",
        "        Inception(112, (144, 288), (32, 64), 64),\n",
        "        Inception(256, (160, 320), (32, 128), 128),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])"
      ],
      "metadata": {
        "id": "UTwHTL8eQUW4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def b5():\n",
        "    return tf.keras.Sequential([\n",
        "        Inception(256, (160, 320), (32, 128), 128),\n",
        "        Inception(384, (192, 384), (48, 128), 128),\n",
        "        tf.keras.layers.GlobalAvgPool2D(),\n",
        "        tf.keras.layers.Flatten()\n",
        "    ])\n",
        "# Recall that this has to be a function that will be passed to\n",
        "# `d2l.train_ch6()` so that model building/compiling need to be within\n",
        "# `strategy.scope()` in order to utilize the CPU/GPU devices that we have\n",
        "def net():\n",
        "    return tf.keras.Sequential([b1(), b2(), b3(), b4(), b5(),\n",
        "                                tf.keras.layers.Dense(10)])"
      ],
      "metadata": {
        "id": "50p9rpZ3QXyF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.random.uniform(shape=(1, 96, 96, 1))\n",
        "for layer in net().layers:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tVnc_FLQdMo",
        "outputId": "f83cdad1-fb1e-44fd-d96c-12eee2c8e66f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential output shape:\t (1, 24, 24, 64)\n",
            "Sequential output shape:\t (1, 12, 12, 192)\n",
            "Sequential output shape:\t (1, 6, 6, 480)\n",
            "Sequential output shape:\t (1, 3, 3, 832)\n",
            "Sequential output shape:\t (1, 1024)\n",
            "Dense output shape:\t (1, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Week12_Batchnormalization"
      ],
      "metadata": {
        "id": "-H4-cyUfQtZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from d2l import tensorflow as d2l\n",
        "\n",
        "\n",
        "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps):\n",
        "    # Compute reciprocal of square root of the moving variance elementwise\n",
        "    inv = tf.cast(tf.math.rsqrt(moving_var + eps), X.dtype)\n",
        "    # Scale and shift\n",
        "    inv *= gamma\n",
        "    Y = X * inv + (beta - moving_mean * inv)\n",
        "    return Y"
      ],
      "metadata": {
        "id": "oZlgp45GQeiy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchNorm(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(BatchNorm, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        weight_shape = [input_shape[-1], ]\n",
        "        # The scale parameter and the shift parameter (model parameters) are\n",
        "        # initialized to 1 and 0, respectively\n",
        "        self.gamma = self.add_weight(name='gamma', shape=weight_shape,\n",
        "            initializer=tf.initializers.ones, trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=weight_shape,\n",
        "            initializer=tf.initializers.zeros, trainable=True)\n",
        "        # The variables that are not model parameters are initialized to 0\n",
        "        self.moving_mean = self.add_weight(name='moving_mean',\n",
        "            shape=weight_shape, initializer=tf.initializers.zeros,\n",
        "            trainable=False)\n",
        "        self.moving_variance = self.add_weight(name='moving_variance',\n",
        "            shape=weight_shape, initializer=tf.initializers.ones,\n",
        "            trainable=False)\n",
        "        super(BatchNorm, self).build(input_shape)\n",
        "\n",
        "    def assign_moving_average(self, variable, value):\n",
        "        momentum = 0.9\n",
        "        delta = variable * momentum + value * (1 - momentum)\n",
        "        return variable.assign(delta)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs, training):\n",
        "        if training:\n",
        "            axes = list(range(len(inputs.shape) - 1))\n",
        "            batch_mean = tf.reduce_mean(inputs, axes, keepdims=True)\n",
        "            batch_variance = tf.reduce_mean(tf.math.squared_difference(\n",
        "                inputs, tf.stop_gradient(batch_mean)), axes, keepdims=True)\n",
        "            batch_mean = tf.squeeze(batch_mean, axes)\n",
        "            batch_variance = tf.squeeze(batch_variance, axes)\n",
        "            mean_update = self.assign_moving_average(\n",
        "                self.moving_mean, batch_mean)\n",
        "            variance_update = self.assign_moving_average(\n",
        "                self.moving_variance, batch_variance)\n",
        "            self.add_update(mean_update)\n",
        "            self.add_update(variance_update)\n",
        "            mean, variance = batch_mean, batch_variance\n",
        "        else:\n",
        "            mean, variance = self.moving_mean, self.moving_variance\n",
        "        output = batch_norm(inputs, moving_mean=mean, moving_var=variance,\n",
        "            beta=self.beta, gamma=self.gamma, eps=1e-5)\n",
        "        return output"
      ],
      "metadata": {
        "id": "J8yfZP1gQzl9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "applying batch normalization linLe Net"
      ],
      "metadata": {
        "id": "73gMY5eZQ9b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recall that this has to be a function that will be passed to `d2l.train_ch6`\n",
        "# so that model building or compiling need to be within `strategy.scope()` in\n",
        "# order to utilize the CPU/GPU devices that we have\n",
        "def net():\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(filters=6, kernel_size=5,\n",
        "                               input_shape=(28, 28, 1)),\n",
        "        BatchNorm(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
        "        tf.keras.layers.Conv2D(filters=16, kernel_size=5),\n",
        "        BatchNorm(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(120),\n",
        "        BatchNorm(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.Dense(84),\n",
        "        BatchNorm(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.Dense(10)]\n",
        "    )"
      ],
      "metadata": {
        "id": "URlBpGDWQ5mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**week12_Resnet**"
      ],
      "metadata": {
        "id": "gkoimG7ZRCwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from d2l import tensorflow as d2l\n",
        "\n",
        "\n",
        "class Residual(tf.keras.Model):  #@save\"\"\"The Residual block of ResNet.\"\"\"\n",
        "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(\n",
        "            num_channels, padding='same', kernel_size=3, strides=strides)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(\n",
        "            num_channels, kernel_size=3, padding='same')\n",
        "        self.conv3 = None\n",
        "        if use_1x1conv:\n",
        "            self.conv3 = tf.keras.layers.Conv2D(\n",
        "                num_channels, kernel_size=1, strides=strides)\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, X):\n",
        "        Y = tf.keras.activations.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3 is not None:\n",
        "            X = self.conv3(X)\n",
        "        Y += X\n",
        "        return tf.keras.activations.relu(Y)"
      ],
      "metadata": {
        "id": "3W452JFfRJfK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk = Residual(3)\n",
        "X = tf.random.uniform((4, 6, 6, 3))\n",
        "Y = blk(X)\n",
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPlKd6G8RQwL",
        "outputId": "0c32ecff-dc46-4e9c-dbdf-d84b0f3cb6a7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 6, 6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blk = Residual(6, use_1x1conv=True, strides=2)\n",
        "blk(X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBEbZ2bQRR6W",
        "outputId": "fa698575-04e7-4f4a-a748-1a81d911d69e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 3, 3, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b1 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])"
      ],
      "metadata": {
        "id": "RgcdoR9ARVZX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResnetBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_channels, num_residuals, first_block=False,\n",
        "                 **kwargs):\n",
        "        super(ResnetBlock, self).__init__(**kwargs)\n",
        "        self.residual_layers = []\n",
        "        for i in range(num_residuals):\n",
        "            if i == 0 and not first_block:\n",
        "                self.residual_layers.append(\n",
        "                    Residual(num_channels, use_1x1conv=True, strides=2))\n",
        "            else:\n",
        "                self.residual_layers.append(Residual(num_channels))\n",
        "\n",
        "    def call(self, X):\n",
        "        for layer in self.residual_layers.layers:\n",
        "            X = layer(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "fueWDRjzRX8C"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b2 = ResnetBlock(64, 2, first_block=True)\n",
        "b3 = ResnetBlock(128, 2)\n",
        "b4 = ResnetBlock(256, 2)\n",
        "b5 = ResnetBlock(512, 2)"
      ],
      "metadata": {
        "id": "egfkjRFuRbUP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we add a global average pooling layer, followed by the fully-connected layer output.\n",
        "\n",
        "# Recall that we define this as a function so we can reuse later and run it\n",
        "# within `tf.distribute.MirroredStrategy`'s scope to utilize various\n",
        "# computational resources, e.g. GPUs. Also note that even though we have\n",
        "# created b1, b2, b3, b4, b5 but we will recreate them inside this function's\n",
        "# scope instead\n",
        "def net():\n",
        "    return tf.keras.Sequential([\n",
        "        # The following layers are the same as b1 that we created earlier\n",
        "        tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same'),\n",
        "        # The following layers are the same as b2, b3, b4, and b5 that we\n",
        "        # created earlier\n",
        "        ResnetBlock(64, 2, first_block=True),\n",
        "        ResnetBlock(128, 2),\n",
        "        ResnetBlock(256, 2),\n",
        "        ResnetBlock(512, 2),\n",
        "        tf.keras.layers.GlobalAvgPool2D(),\n",
        "        tf.keras.layers.Dense(units=10)])"
      ],
      "metadata": {
        "id": "RQkC_F9pRfgi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.random.uniform(shape=(1, 224, 224, 1))\n",
        "for layer in net().layers:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBfdXNNkRloL",
        "outputId": "cca1c35a-8116-4fb5-f40c-a21f34eb6f91"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2D output shape:\t (1, 112, 112, 64)\n",
            "BatchNormalization output shape:\t (1, 112, 112, 64)\n",
            "Activation output shape:\t (1, 112, 112, 64)\n",
            "MaxPooling2D output shape:\t (1, 56, 56, 64)\n",
            "ResnetBlock output shape:\t (1, 56, 56, 64)\n",
            "ResnetBlock output shape:\t (1, 28, 28, 128)\n",
            "ResnetBlock output shape:\t (1, 14, 14, 256)\n",
            "ResnetBlock output shape:\t (1, 7, 7, 512)\n",
            "GlobalAveragePooling2D output shape:\t (1, 512)\n",
            "Dense output shape:\t (1, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-JkmVKRwR4AN"
      }
    }
  ]
}